# pytorch_optimizer_ranger
support going on training perfectly when training stopped.

when use optimizer.state_dict() and optimizer.load_state_dict(), it can save and load all data of ranger(such as radam_buffer).  
